{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assignment 4 FOML\n",
      "Question 5.)\n",
      "\n",
      "*** PART_A ***\n",
      "Iteratiion number is 1 and loss value is 0.5569500797547652\n",
      "Iteratiion number is 11 and loss value is 0.5527434547813901\n",
      "Iteratiion number is 21 and loss value is 0.5486156177889855\n",
      "Iteratiion number is 31 and loss value is 0.5445502635976432\n",
      "Iteratiion number is 41 and loss value is 0.5405404093716722\n",
      "Iteratiion number is 51 and loss value is 0.5365827998335017\n",
      "Iteratiion number is 61 and loss value is 0.5326756772349874\n",
      "Iteratiion number is 71 and loss value is 0.5288178901925459\n",
      "Iteratiion number is 81 and loss value is 0.5250085368196484\n",
      "Iteratiion number is 91 and loss value is 0.5212468215749928\n",
      "\n",
      "*** PART_B (i) ***\n",
      "Writing the Logistic Model as P(ŷ=1|x1,x2) = 1 / (1 + exp(-fθ(x1, x2)))\n",
      "fθ(x1, x2) = θ0 + θ1*x1 + θ2*x2\n",
      "Cross Entropy Error Function can be writen as E = -(1/m) * Σ[y*log(P) + (1-y)*log(1-P)]\n",
      "\n",
      "*** PART_B (ii) ***\n",
      "here is the updated weight <θ> is  [-1.00316626  1.50535086  0.50196867]\n",
      "Logistic_Regression_Model_After_One_Iteration -\n",
      "fθ(x1, x2) = -1.0032 + 1.5054*x1 + 0.5020*x2\n",
      "\n",
      "*** PART_B (iii) ***\n",
      "Model Evaluation at Convergence:\n",
      "accuracy is 66.67%\n",
      "precision is 0.60\n",
      "recall is 1.00\n",
      "prediction is [1 1 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Question no. 5\n",
    "\n",
    "# Here i am importing allthe required library for this assignment.\n",
    "# the numPy library which i impoted here is used for numerical value computations.\n",
    "import numpy as np\n",
    "# the sklern metrics gives us a such type of tools which is used for the evaluating learning models.\n",
    "# precision score is tells about the precision of the prdtn.\n",
    "# and the recall_score is tells about the recall of the prdtn.\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# here is the sg_moid function, that was helps me to maps the input to the probablety b/w 0 and 1.\n",
    "# the motivation behing this functin is to calculate the probability\n",
    "def sg_moid(z):\n",
    "    exxpr_neg_z = np.exp(-z)\n",
    "    y = (1 + exxpr_neg_z)\n",
    "    x = 1 / y\n",
    "    return x\n",
    "\n",
    "# here is hte cross entropy for the Error Function\n",
    "# here i am evaluating hte cross entropyfor the evaluating error for the binary classification\n",
    "def crss_entrpy(y_truuu, y_prddd):\n",
    "    eps = 1e-15\n",
    "    y_prddd = np.clip(y_prddd, eps, 1 - eps)\n",
    "    x = y_truuu * np.log(y_prddd)\n",
    "    y = (1 - y_truuu) * np.log(1 - y_prddd)\n",
    "    z = -np.mean(x + y)\n",
    "    return z\n",
    "\n",
    "# here si the function of the grdtn diescent tranning func\n",
    "def ttraiin_loggdtii_regrsn(X, y, thta, lrn_r_rate, ittrn):\n",
    "    m = len(y) \n",
    "    for i in range(ittrn):\n",
    "        # here i am compuiteing the models output\n",
    "        z = np.dot(X, thta)\n",
    "        prdtn = sg_moid(z) \n",
    "        \n",
    "        # calculating the value for the grdtn at θ\n",
    "        grdtn = np.dot(X.T, (prdtn - y)) / m\n",
    "        \n",
    "        # here updateing the θ by using gradiant descent\n",
    "        xxyx = lrn_r_rate * grdtn\n",
    "        thta = thta - xxyx\n",
    "        \n",
    "        # Calculating and  print the loss value at each itteration\n",
    "        lsss = crss_entrpy(y, prdtn)\n",
    "        if(i % 10 == 0):\n",
    "            print(\"Iteratiion number is {} and loss value is {}\".format(i+1, lsss))\n",
    "    return thta\n",
    "\n",
    "# here is te logisstic moodel and crooss entroppy error functions\n",
    "def printing_the_logggstc_mdl_and_eroror_functn():\n",
    "    print(\"\\n*** PART_B (i) ***\")\n",
    "    print(\"Writing the Logistic Model as P(ŷ=1|x1,x2) = 1 / (1 + exp(-fθ(x1, x2)))\")\n",
    "    print(\"fθ(x1, x2) = θ0 + θ1*x1 + θ2*x2\")\n",
    "    print(\"Cross Entropy Error Function can be writen as E = -(1/m) * Σ[y*log(P) + (1-y)*log(1-P)]\")\n",
    "\n",
    "def oneee_Ittrr_func_updatee(X, y, thta, lrn_r_rate):\n",
    "    m = len(y) \n",
    "    # here i am computing the linear combbination\n",
    "    z = np.dot(X, thta) \n",
    "    prdtn = sg_moid(z)\n",
    "    yx = (prdtn - y)\n",
    "    xy = np.dot(X.T, yx) / m \n",
    "    grdtn = xy # here calculating the value of the gradiant\n",
    "    zz = lrn_r_rate * grdtn\n",
    "    updated_thta = thta - zz  # Update weights using grdtn descent\n",
    "    \n",
    "    # Print the updated θ\n",
    "    print(\"\\n*** PART_B (ii) ***\")\n",
    "    print(\"here is the updated weight <θ> is \", updated_thta)\n",
    "    print(\"Logistic_Regression_Model_After_One_Iteration -\")\n",
    "    print(f\"fθ(x1, x2) = {updated_thta[0]:.4f} + {updated_thta[1]:.4f}*x1 + {updated_thta[2]:.4f}*x2\")\n",
    "    \n",
    "    return updated_thta\n",
    "\n",
    "# i am predicting using the models\n",
    "def prdct(X, thta):\n",
    "    # calculating the probability and teh threshold them at 0.50\n",
    "    prob_lity = sg_moid(np.dot(X, thta))\n",
    "    binry = prob_lity >= 0.5\n",
    "    return (binry).astype(int)\n",
    "\n",
    "# here i am evaluating the mdl performanvce by compuing the accur_cy, precision, recall values\n",
    "def prfm_eval_mdl(X, y, thta):\n",
    "    prdtn = prdct(X, thta)  \n",
    "    accur_cy = np.mean(prdtn == y)\n",
    "    precsin = precision_score(y, prdtn)\n",
    "    rc_call = recall_score(y, prdtn)\n",
    "    \n",
    "    # Print evaluation metrics\n",
    "    print(\"\\n*** PART_B (iii) ***\")\n",
    "    print(\"Model Evaluation at Convergence:\")\n",
    "    print(\"accuracy is {:.2f}%\".format(accur_cy * 100))\n",
    "    print(\"precision is {:.2f}\".format(precsin))\n",
    "    print(\"recall is {:.2f}\".format(rc_call))\n",
    "    print(\"prediction is\", prdtn)\n",
    "\n",
    "# here is  the training and  hte test data\n",
    "trn_dta = np.array([\n",
    "    [0.346, 0.780, 0],\n",
    "    [0.303, 0.439, 0],\n",
    "    [0.358, 0.729, 0],\n",
    "    [0.602, 0.863, 1],\n",
    "    [0.790, 0.753, 1],\n",
    "    [0.611, 0.965, 1]\n",
    "])\n",
    "\n",
    "tst_dta = np.array([\n",
    "    [0.959, 0.382, 0],\n",
    "    [0.750, 0.306, 0],\n",
    "    [0.395, 0.760, 0],\n",
    "    [0.823, 0.764, 1],\n",
    "    [0.761, 0.874, 1],\n",
    "    [0.844, 0.435, 1]\n",
    "])\n",
    "\n",
    "# here i am spliting the colunmns and the labels for teh training and the testing\n",
    "X_trni = np.c_[np.ones(len(trn_dta)), trn_dta[:, :2]]  \n",
    "y_trni = trn_dta[:, 2]\n",
    "X_tsti = np.c_[np.ones(len(tst_dta)), tst_dta[:, :2]]  \n",
    "y_tsti = tst_dta[:, 2]\n",
    "\n",
    "# here i ma giving the initial weights and the earning rates.\n",
    "thta_initial = np.array([-1, 1.5, 0.5])\n",
    "lrn_r_rate = 0.1\n",
    "ittrn = 100  # No. of ittrn for grdtn descent\n",
    "print(\"Assignment 4 FOML\")\n",
    "print(\"Question 5.)\")\n",
    "# PART A\n",
    "print(\"\\n*** PART_A ***\")\n",
    "thta_final = ttraiin_loggdtii_regrsn(X_trni, y_trni, thta_initial, lrn_r_rate, ittrn)\n",
    "\n",
    "# PART B(i)\n",
    "printing_the_logggstc_mdl_and_eroror_functn()\n",
    "\n",
    "# PART B(ii)\n",
    "thta_one_iteration = oneee_Ittrr_func_updatee(X_trni, y_trni, thta_initial, lrn_r_rate)\n",
    "\n",
    "# PART B(iii)\n",
    "prfm_eval_mdl(X_tsti, y_tsti, thta_final)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting - Train RMSLE: 0.0829, Test RMSLE: 0.1369\n",
      "Random Forest - Train RMSLE: 0.0605, Test RMSLE: 0.1534\n",
      "Best Model - Gradient Boosting, Test RMSLE - 0.13695\n"
     ]
    }
   ],
   "source": [
    "# Question no. 6\n",
    "\n",
    "# here i am immport all the necesssary inbuilt librariies.\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# to check work flow of the program\n",
    "ct = 1\n",
    "\n",
    "# Now loading the trainig and the test data from the system, whihcih is provided in the contest.\n",
    "test_dta_nput = pd.read_csv('test.csv')\n",
    "train_dta_nput = pd.read_csv('train.csv')\n",
    "\n",
    "# check each line work properly and wrok flow\n",
    "if(ct == 0):\n",
    "    print(\"{}\\n\".format(ct))\n",
    "    cnt = ct + 1\n",
    "\n",
    "# here i am defining the target and the features\n",
    "trgt = 'SalePrice'\n",
    "ftrs = []\n",
    "for colll in train_dta_nput.columns:\n",
    "    if colll != trgt:\n",
    "        ftrs.append(colll)\n",
    "\n",
    "# nsaperating out the target variables from the  feature of the data set.\n",
    "y = train_dta_nput[trgt]\n",
    "X = train_dta_nput[ftrs]\n",
    "\n",
    "# preprocessing in this task is to handeling all the missing values and also the categorical data.\n",
    "\n",
    "# and here is the numerical columns or features.\n",
    "numerical_cols = X.select_dtypes(exclude=['object']).columns\n",
    "\n",
    "# hher is the categorical columns oor features.\n",
    "categorical_cols = X.select_dtypes(include=['object']).columns\n",
    "\n",
    "# check each line work properly and wrok flow\n",
    "if(ct == 0):\n",
    "    print(\"{}\\n\".format(ct))\n",
    "    cnt = ct + 1\n",
    "\n",
    "# all the preprocessing task we take it into the pipeline to better resource utilisation.\n",
    "# and for all the numerical datas, we are filling the missing values by replacing it with the median.\n",
    "numerical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "# and for all the categorical datas, we are filling the missing values by replacing it with the most frequent values in the dataset and also applying the onehot encoding\n",
    "catego_riical_trans_former = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('onehot', OneHotEncoder(handle_unknown='ignore', sparse_output=False))  # Corrected here\n",
    "])\n",
    "\n",
    "# after all this now combining the transformation into the single preprocesssor.\n",
    "pre_process_or = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numerical_transformer, numerical_cols),\n",
    "        ('cat', catego_riical_trans_former, categorical_cols)\n",
    "    ])\n",
    "\n",
    "# check each line work properly and wrok flow\n",
    "if(ct == 0):\n",
    "    print(\"{}\\n\".format(ct))\n",
    "    cnt = ct + 1\n",
    "\n",
    "# basically here i am defining hte twoo different models, that can i used here for the training purpose.\n",
    "modlsss = {\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42)\n",
    "}\n",
    "\n",
    "# here i am created the function so that it can train our models, and also making the predictions after that i will going to calculate RMSLE\n",
    "def tranii_aandd_evlutn(model, X_train, y_train, X_test, y_test):\n",
    "    # creating the pipeline to preprocessor the data faster for the models\n",
    "    pipelining = Pipeline(steps=[('preprocessor', pre_process_or), ('model', model)])\n",
    "    \n",
    "    # here i am train my models\n",
    "    pipelining.fit(X_train, y_train)\n",
    "    \n",
    "    # after training the modele then i make a predictions with the models.\n",
    "    y_predtn_testii = pipelining.predict(X_test)\n",
    "    y_predtn_tranii = pipelining.predict(X_train)\n",
    "    \n",
    "    # after all this i am evaluating the RMSLE value.\n",
    "    rmsle_testii = np.sqrt(mean_squared_log_error(y_test, y_predtn_testii))\n",
    "    rmsle_tranii = np.sqrt(mean_squared_log_error(y_train, y_predtn_tranii))\n",
    "    \n",
    "    return rmsle_tranii, pipelining, rmsle_testii\n",
    "\n",
    "# check each line work properly and wrok flow\n",
    "if(ct == 0):\n",
    "    print(\"{}\\n\".format(ct))\n",
    "    cnt = ct + 1\n",
    "\n",
    "# now spliting the dataseet into the training and the validation sets\n",
    "X_traniii, X_validtn, y_traniii, y_validtn = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# here i am evaluating the both models efficientlky.\n",
    "rssslt = {}\n",
    "for mdl_nam_is, mdl in modlsss.items():\n",
    "    rmsle_traini, pipeline, rmsle_testi = tranii_aandd_evlutn(mdl, X_traniii, y_traniii, X_validtn, y_validtn)\n",
    "    rssslt[mdl_nam_is] = {\n",
    "        'Trning RMSLE': rmsle_traini,\n",
    "        'Tsting RMSLE': rmsle_testi,\n",
    "        'Pipelining': pipeline\n",
    "    }\n",
    "\n",
    "# check each line work properly and wrok flow\n",
    "if(ct == 0):\n",
    "    print(\"{}\\n\".format(ct))\n",
    "    cnt = ct + 1\n",
    "\n",
    "# After all this i am printing the results and all comparing the models\n",
    "for mdl_nm, rslt in rssslt.items():\n",
    "    print(\"{} - Train RMSLE: {:.4f}, Test RMSLE: {:.4f}\".format(mdl_nm, rslt['Trning RMSLE'], rslt['Tsting RMSLE']))\n",
    "\n",
    "# After getting the RSMLE values for both the models now choosing the best model based on it.\n",
    "bestest_mdl_nm = min(rssslt, key=lambda x: rssslt[x]['Tsting RMSLE'])\n",
    "bestest_mdl_pipe_line = rssslt[bestest_mdl_nm]['Pipelining']\n",
    "\n",
    "# check each line work properly and wrok flow\n",
    "if(ct == 0):\n",
    "    print(\"{}\\n\".format(ct))\n",
    "    cnt = ct + 1\n",
    "\n",
    "# now maaking the predictionss by using the test dataset so that i can submit it into a Kaggle.\n",
    "X_testing_finll = test_dta_nput[ftrs]\n",
    "y_predtn_finll = bestest_mdl_pipe_line.predict(X_testing_finll)\n",
    "\n",
    "# here i am checking for the large values of the prediction.\n",
    "y_predtn_finlll = np.clip(y_predtn_finll, a_min=0, a_max=1e6)\n",
    "\n",
    "# check each line work properly and wrok flow\n",
    "if(ct == 0):\n",
    "    print(\"{}\\n\".format(ct))\n",
    "    cnt = ct + 1\n",
    "\n",
    "# after done with alll hte process i am creating the submission file for submission.\n",
    "sub_mission_files = pd.DataFrame({\n",
    "    'Id': test_dta_nput['Id'],\n",
    "    'SalePrice': y_predtn_finlll \n",
    "})\n",
    "\n",
    "# after generatin the submission file now its time save it into the system.\n",
    "sub_mission_files.to_csv('submission_file_for_kaggle.csv', index=False)\n",
    "\n",
    "print(\"Best Model - {}, Test RMSLE - {:.5f}\".format(bestest_mdl_nm, rssslt[bestest_mdl_nm]['Tsting RMSLE']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
